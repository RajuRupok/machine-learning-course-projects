{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Experiments with MNIST Dataset\n",
    "In this notebook, we explore the MNIST dataset with CNN models by performing various experiments:\n",
    "- Changing the number of filters in Conv2D layers.\n",
    "- Adding or removing layers.\n",
    "- Trying different optimizers and learning rates.\n",
    "- Modifying the number of epochs.\n",
    "- Adding dropout layers to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000,) (10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import struct\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Helper function to load MNIST images\n",
    "def load_mnist_images(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        _, num_images, rows, cols = struct.unpack('>IIII', f.read(16))\n",
    "        data = np.fromfile(f, dtype=np.uint8).reshape(num_images, rows, cols)\n",
    "    return data / 255.0\n",
    "\n",
    "# Helper function to load MNIST labels\n",
    "def load_mnist_labels(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        _, num_labels = struct.unpack('>II', f.read(8))\n",
    "        labels = np.fromfile(f, dtype=np.uint8)\n",
    "    return labels\n",
    "\n",
    "# File paths (update these to your local paths)\n",
    "train_images_path = 'train-images.idx3-ubyte'\n",
    "train_labels_path = 'train-labels.idx1-ubyte'\n",
    "test_images_path = 't10k-images.idx3-ubyte'\n",
    "test_labels_path = 't10k-labels.idx1-ubyte'\n",
    "\n",
    "# Load datasets\n",
    "train_images = load_mnist_images(train_images_path)\n",
    "train_labels = load_mnist_labels(train_labels_path)\n",
    "test_images = load_mnist_images(test_images_path)\n",
    "test_labels = load_mnist_labels(test_labels_path)\n",
    "\n",
    "# Reshape images to add channel dimension\n",
    "train_images = train_images[..., np.newaxis]\n",
    "test_images = test_images[..., np.newaxis]\n",
    "\n",
    "print(train_images.shape, train_labels.shape, test_images.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sadma\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 13ms/step - accuracy: 0.9155 - loss: 0.2659 - val_accuracy: 0.9865 - val_loss: 0.0421\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9880 - loss: 0.0403 - val_accuracy: 0.9878 - val_loss: 0.0385\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9908 - loss: 0.0284 - val_accuracy: 0.9919 - val_loss: 0.0277\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9939 - loss: 0.0189 - val_accuracy: 0.9885 - val_loss: 0.0398\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9946 - loss: 0.0157 - val_accuracy: 0.9916 - val_loss: 0.0288\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9966 - loss: 0.0113 - val_accuracy: 0.9925 - val_loss: 0.0285\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9966 - loss: 0.0110 - val_accuracy: 0.9901 - val_loss: 0.0349\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9972 - loss: 0.0082 - val_accuracy: 0.9888 - val_loss: 0.0488\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9976 - loss: 0.0080 - val_accuracy: 0.9926 - val_loss: 0.0329\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9894 - val_loss: 0.0454\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0616\n",
      "Test accuracy with more filters: 0.9894000291824341\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model with more filters\n",
    "def create_cnn_model_more_filters():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "model = create_cnn_model_more_filters()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy with more filters: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Changing number of filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 227ms/step - accuracy: 0.8522 - loss: 0.4775 - val_accuracy: 0.9863 - val_loss: 0.0479\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m427s\u001b[0m 228ms/step - accuracy: 0.9863 - loss: 0.0487 - val_accuracy: 0.9877 - val_loss: 0.0414\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 219ms/step - accuracy: 0.9918 - loss: 0.0289 - val_accuracy: 0.9886 - val_loss: 0.0396\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m414s\u001b[0m 221ms/step - accuracy: 0.9943 - loss: 0.0194 - val_accuracy: 0.9915 - val_loss: 0.0299\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m412s\u001b[0m 220ms/step - accuracy: 0.9955 - loss: 0.0136 - val_accuracy: 0.9879 - val_loss: 0.0489\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m408s\u001b[0m 218ms/step - accuracy: 0.9959 - loss: 0.0150 - val_accuracy: 0.9898 - val_loss: 0.0468\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m411s\u001b[0m 219ms/step - accuracy: 0.9968 - loss: 0.0110 - val_accuracy: 0.9902 - val_loss: 0.0461\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m419s\u001b[0m 223ms/step - accuracy: 0.9972 - loss: 0.0100 - val_accuracy: 0.9901 - val_loss: 0.0398\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m426s\u001b[0m 227ms/step - accuracy: 0.9975 - loss: 0.0082 - val_accuracy: 0.9902 - val_loss: 0.0438\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m415s\u001b[0m 221ms/step - accuracy: 0.9979 - loss: 0.0072 - val_accuracy: 0.9900 - val_loss: 0.0470\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 60ms/step - accuracy: 0.9892 - loss: 0.0559\n",
      "Test accuracy with more filters: 0.9900000095367432\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model with more filters\n",
    "def create_cnn_model_extreme_filters():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(512, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(512, (3, 3), activation='relu'),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(15, activation='relu'),\n",
    "        layers.Dense(15, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "model = create_cnn_model_extreme_filters()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy with more filters: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Adding Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.8385 - loss: 0.4993 - val_accuracy: 0.9818 - val_loss: 0.0550\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9682 - loss: 0.1049 - val_accuracy: 0.9885 - val_loss: 0.0350\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9772 - loss: 0.0775 - val_accuracy: 0.9911 - val_loss: 0.0262\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9806 - loss: 0.0634 - val_accuracy: 0.9917 - val_loss: 0.0277\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9822 - loss: 0.0605 - val_accuracy: 0.9907 - val_loss: 0.0264\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9844 - loss: 0.0496 - val_accuracy: 0.9919 - val_loss: 0.0233\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9853 - loss: 0.0434 - val_accuracy: 0.9931 - val_loss: 0.0230\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9860 - loss: 0.0472 - val_accuracy: 0.9931 - val_loss: 0.0219\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9877 - loss: 0.0399 - val_accuracy: 0.9933 - val_loss: 0.0213\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9882 - loss: 0.0371 - val_accuracy: 0.9942 - val_loss: 0.0202\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0242\n",
      "Test accuracy with dropout layers: 0.9941999912261963\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model with dropout layers\n",
    "def create_cnn_model_with_dropout():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(10, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile and train the model\n",
    "model = create_cnn_model_with_dropout()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy with dropout layers: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Trying SGD optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.6857 - loss: 1.0646 - val_accuracy: 0.9583 - val_loss: 0.1365\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9577 - loss: 0.1410 - val_accuracy: 0.9759 - val_loss: 0.0804\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 12ms/step - accuracy: 0.9721 - loss: 0.0903 - val_accuracy: 0.9809 - val_loss: 0.0632\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9779 - loss: 0.0697 - val_accuracy: 0.9830 - val_loss: 0.0525\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9832 - loss: 0.0558 - val_accuracy: 0.9838 - val_loss: 0.0499\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9851 - loss: 0.0481 - val_accuracy: 0.9855 - val_loss: 0.0464\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9864 - loss: 0.0448 - val_accuracy: 0.9866 - val_loss: 0.0428\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0383 - val_accuracy: 0.9859 - val_loss: 0.0425\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9898 - loss: 0.0332 - val_accuracy: 0.9891 - val_loss: 0.0331\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 12ms/step - accuracy: 0.9909 - loss: 0.0303 - val_accuracy: 0.9890 - val_loss: 0.0331\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0417\n",
      "Test accuracy with SGD optimizer: 0.9890000224113464\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model with SGD optimizer\n",
    "model = create_cnn_model_more_filters()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy with SGD optimizer: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Trying RMSprop Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 14ms/step - accuracy: 0.9148 - loss: 0.2639 - val_accuracy: 0.9884 - val_loss: 0.0342\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9882 - loss: 0.0384 - val_accuracy: 0.9899 - val_loss: 0.0362\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0253 - val_accuracy: 0.9902 - val_loss: 0.0362\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9945 - loss: 0.0183 - val_accuracy: 0.9915 - val_loss: 0.0339\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9957 - loss: 0.0145 - val_accuracy: 0.9923 - val_loss: 0.0318\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.9911 - val_loss: 0.0407\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9978 - loss: 0.0082 - val_accuracy: 0.9921 - val_loss: 0.0402\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9925 - val_loss: 0.0439\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 13ms/step - accuracy: 0.9981 - loss: 0.0072 - val_accuracy: 0.9930 - val_loss: 0.0430\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 13ms/step - accuracy: 0.9985 - loss: 0.0057 - val_accuracy: 0.9929 - val_loss: 0.0512\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0691\n",
      "Test accuracy with SGD optimizer: 0.992900013923645\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model with RMSprop optimizer\n",
    "model = create_cnn_model_more_filters()\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.001),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy with SGD optimizer: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5: Trying SGD Optimizer with Dropout Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.5268 - loss: 1.3730 - val_accuracy: 0.9423 - val_loss: 0.2051\n",
      "Epoch 2/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.8932 - loss: 0.3430 - val_accuracy: 0.9630 - val_loss: 0.1262\n",
      "Epoch 3/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9290 - loss: 0.2378 - val_accuracy: 0.9698 - val_loss: 0.1033\n",
      "Epoch 4/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9384 - loss: 0.2044 - val_accuracy: 0.9738 - val_loss: 0.0796\n",
      "Epoch 5/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.1697 - val_accuracy: 0.9760 - val_loss: 0.0724\n",
      "Epoch 6/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9569 - loss: 0.1426 - val_accuracy: 0.9793 - val_loss: 0.0628\n",
      "Epoch 7/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9586 - loss: 0.1353 - val_accuracy: 0.9814 - val_loss: 0.0571\n",
      "Epoch 8/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9626 - loss: 0.1272 - val_accuracy: 0.9825 - val_loss: 0.0536\n",
      "Epoch 9/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9637 - loss: 0.1187 - val_accuracy: 0.9839 - val_loss: 0.0502\n",
      "Epoch 10/10\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 6ms/step - accuracy: 0.9667 - loss: 0.1118 - val_accuracy: 0.9839 - val_loss: 0.0486\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9808 - loss: 0.0593\n",
      "Test accuracy with SGD optimizer: 0.9839000105857849\n"
     ]
    }
   ],
   "source": [
    "# Define a CNN model with SGD optimizer\n",
    "model = create_cnn_model_with_dropout()\n",
    "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy with SGD optimizer: {test_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6: Weak CNN Model Architecture\n",
    "This model has fewer layers and uses minimal filters to ensure low performance.\n",
    "\n",
    "1. Reduce Model Complexity:\n",
    "\n",
    "    Use fewer layers and filters.\n",
    "\n",
    "    Avoid deeper architectures.\n",
    "\n",
    "2. Poor Training Configuration:\n",
    "    \n",
    "    Use a high learning rate or no learning rate tuning.\n",
    "    \n",
    "    Use a non-optimal optimizer.\n",
    "\n",
    "3. Minimal Training:\n",
    "    \n",
    "    Train the model for very few epochs.\n",
    "\n",
    "4. No Regularization:\n",
    "    \n",
    "    Avoid techniques like dropout or L2 regularization that help generalization.\n",
    "\n",
    "5. Poor Input Representation:\n",
    "    \n",
    "    Avoid normalizing input properly (optional, but usually not necessary for weak performance).\n",
    "\n",
    "Here’s a simple weak model configuration:\n",
    "\n",
    "1 Convolutional Layer: With only 4 filters.\n",
    "No Pooling Layer: Skipping pooling can reduce the feature extraction power.\n",
    "directly flatten without pooling\n",
    "Small Dense Layer: Use only a small dense layer for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.7653 - loss: 0.7419 - val_accuracy: 0.9212 - val_loss: 0.2782\n",
      "Epoch 2/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9266 - loss: 0.2581 - val_accuracy: 0.9451 - val_loss: 0.1878\n",
      "Epoch 3/3\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9513 - loss: 0.1681 - val_accuracy: 0.9608 - val_loss: 0.1393\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9549 - loss: 0.1608\n",
      "Test accuracy of weak model: 0.9607999920845032\n"
     ]
    }
   ],
   "source": [
    "# Define a weak CNN model\n",
    "def create_very_weak_cnn_model():\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(4, (3, 3), activation='relu', input_shape=(28, 28, 1)),  # Only 4 filters\n",
    "        layers.Flatten(),  # Directly flatten without pooling\n",
    "        layers.Dense(10, activation='relu'),  # Only 10 neurons in dense layer\n",
    "        layers.Dense(10, activation='softmax')  # Output layer\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Compile the weak model\n",
    "model = create_very_weak_cnn_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the weak model for few epochs\n",
    "history = model.fit(train_images, train_labels, epochs=3, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the weak model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy of weak model: {test_acc}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
